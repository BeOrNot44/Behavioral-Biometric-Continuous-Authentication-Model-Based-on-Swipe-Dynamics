{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn import metrics \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "# to obtain the mutual information values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"SWIPES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22400, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.drop([\"subject\"],axis =1)\n",
    "y = data[\"subject\"]\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17920, 30), (17920,), (4480, 30), (4480,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "ML_Model = []\n",
    "accuracy = []\n",
    "EER = []\n",
    "Time = []\n",
    "f1_score = []\n",
    "recall = []\n",
    "precision = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(model, a,e,l,b,c,d):\n",
    "  ML_Model.append(model)\n",
    "  accuracy.append(round(a, 3))\n",
    "  EER.append(e)\n",
    "  Time.append(l)\n",
    "  f1_score.append(round(b, 3))\n",
    "  recall.append(round(c, 3))\n",
    "  precision.append(round(d, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.pipeline import Pipeline\n",
    "\n",
    "# instantiate the model\n",
    "log = LogisticRegression()\n",
    "\n",
    "# fit the model \n",
    "log.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "y_train_log = log.predict(X_train)\n",
    "start_time = time.clock()\n",
    "y_test_log = log.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_train_log = metrics.accuracy_score(y_train,y_train_log)\n",
    "acc_test_log = metrics.accuracy_score(y_test,y_test_log)\n",
    "\n",
    "f1_score_train_log = metrics.f1_score(y_train,y_train_log, average='macro')\n",
    "f1_score_test_log = metrics.f1_score(y_test,y_test_log, average='macro')\n",
    "\n",
    "recall_score_train_log = metrics.recall_score(y_train,y_train_log, average='macro')\n",
    "recall_score_test_log = metrics.recall_score(y_test,y_test_log, average='macro')\n",
    "\n",
    "precision_score_train_log = metrics.precision_score(y_train,y_train_log, average='macro')\n",
    "precision_score_test_log = metrics.precision_score(y_test,y_test_log, average='macro')\n",
    "\n",
    "EER_log =\"{:.4f}\".format(mean_squared_error(y_test, y_test_log))\n",
    "time= time.clock() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "storeResults('Logistic Regression',acc_test_log,EER_log,time,f1_score_test_log,\n",
    "             recall_score_train_log,precision_score_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Nearest Neighbors Classifier model\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# instantiate the model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# fit the model \n",
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "import time\n",
    "y_train_knn = knn.predict(X_train)\n",
    "start_time= time.clock()\n",
    "y_test_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9921875\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy,f1_score,Recall,precision of the model performance\n",
    "acc_train_knn = metrics.accuracy_score(y_train,y_train_knn)\n",
    "acc_test_knn = metrics.accuracy_score(y_test,y_test_knn)\n",
    "\n",
    "f1_score_train_knn = metrics.f1_score(y_train,y_train_knn, average='macro')\n",
    "f1_score_test_knn = metrics.f1_score(y_test,y_test_knn, average='macro')\n",
    "\n",
    "recall_score_train_knn = metrics.recall_score(y_train,y_train_knn, average='macro')\n",
    "recall_score_test_knn = metrics.recall_score(y_test,y_test_knn, average='macro')\n",
    "\n",
    "precision_score_train_knn = metrics.precision_score(y_train,y_train_knn, average='macro')\n",
    "precision_score_test_knn = metrics.precision_score(y_test,y_test_knn, average='macro')\n",
    "\n",
    "EER_knn =\"{:.4f}\".format(mean_squared_error(y_test, y_test_knn))\n",
    "\n",
    "time1 = time.clock() - start_time\n",
    "print(acc_test_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "\n",
    "storeResults('K-Nearest Neighbors',acc_test_knn,EER_knn,time1,f1_score_test_knn,\n",
    "             recall_score_train_knn,precision_score_train_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'gamma': [0.1], 'kernel': ['rbf', 'linear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Classifier model \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# defining parameter range\n",
    "param_grid = {'gamma': [0.1],'kernel': ['rbf','linear']}\n",
    "\n",
    "svc = GridSearchCV(SVC(), param_grid)\n",
    "\n",
    "# fitting the model for grid search\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "import time\n",
    "y_train_svc = svc.predict(X_train)\n",
    "start_time= time.clock()\n",
    "y_test_svc = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine : Accuracy on training Data:  0.99609375\n",
      "Support Vector Machine : Accuracy on test Data:  0.9854910714285714\n",
      "\n",
      "Support Vector Machine : f1_score on training Data:  0.9960791053581352\n",
      "Support Vector Machine : f1_score on test Data:  0.9858358944410723\n",
      "\n",
      "Support Vector Machine : Recall on training Data:  0.9960859714252387\n",
      "Support Vector Machine : Recall on test Data:  0.9856852117057558\n",
      "\n",
      "Support Vector Machine : precision on training Data:  0.9960861806755468\n",
      "Support Vector Machine : precision on test Data:  0.9866058983581701\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
    "\n",
    "acc_train_svc = metrics.accuracy_score(y_train,y_train_svc)\n",
    "acc_test_svc = metrics.accuracy_score(y_test,y_test_svc)\n",
    "print(\"Support Vector Machine : Accuracy on training Data: \",acc_train_svc)\n",
    "print(\"Support Vector Machine : Accuracy on test Data: \",acc_test_svc)\n",
    "print()\n",
    "\n",
    "f1_score_train_svc = metrics.f1_score(y_train,y_train_svc, average='macro')\n",
    "f1_score_test_svc = metrics.f1_score(y_test,y_test_svc, average='macro')\n",
    "print(\"Support Vector Machine : f1_score on training Data: \",f1_score_train_svc)\n",
    "print(\"Support Vector Machine : f1_score on test Data: \",f1_score_test_svc)\n",
    "print()\n",
    "\n",
    "recall_score_train_svc = metrics.recall_score(y_train,y_train_svc, average='macro')\n",
    "recall_score_test_svc = metrics.recall_score(y_test,y_test_svc, average='macro')\n",
    "print(\"Support Vector Machine : Recall on training Data: \",recall_score_train_svc)\n",
    "print(\"Support Vector Machine : Recall on test Data: \",recall_score_test_svc)\n",
    "print()\n",
    "\n",
    "precision_score_train_svc = metrics.precision_score(y_train,y_train_svc, average='macro')\n",
    "precision_score_test_svc = metrics.precision_score(y_test,y_test_svc, average='macro')\n",
    "print(\"Support Vector Machine : precision on training Data: \",precision_score_train_svc)\n",
    "print(\"Support Vector Machine : precision on test Data: \",precision_score_test_svc)\n",
    "\n",
    "EER_svc =\"{:.4f}\".format(mean_squared_error(y_test, y_test_knn))\n",
    "time= time.clock() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "\n",
    "storeResults('Support Vector Machine',acc_test_svc,EER_svc,time,f1_score_test_svc,\n",
    "             recall_score_train_svc,precision_score_train_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Classifier Model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# instantiate the model\n",
    "nb=  GaussianNB()\n",
    "\n",
    "# fit the model \n",
    "nb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "import time\n",
    "y_train_nb = nb.predict(X_train)\n",
    "start_time= time.clock() \n",
    "y_test_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier : Accuracy on training Data:  0.8977678571428571\n",
      "Naive Bayes Classifier : Accuracy on test Data:  0.8879464285714286\n",
      "\n",
      "Naive Bayes Classifier : f1_score on training Data:  0.8983037451563349\n",
      "Naive Bayes Classifier : f1_score on test Data:  0.889275049904357\n",
      "\n",
      "Naive Bayes Classifier : Recall on training Data:  0.8976055360702959\n",
      "Naive Bayes Classifier : Recall on test Data:  0.8894484348384594\n",
      "\n",
      "Naive Bayes Classifier : precision on training Data:  0.9010269200621066\n",
      "Naive Bayes Classifier : precision on test Data:  0.8933456881076661\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
    "\n",
    "acc_train_nb = metrics.accuracy_score(y_train,y_train_nb)\n",
    "acc_test_nb = metrics.accuracy_score(y_test,y_test_nb)\n",
    "print(\"Naive Bayes Classifier : Accuracy on training Data: \",acc_train_nb)\n",
    "print(\"Naive Bayes Classifier : Accuracy on test Data: \",acc_test_nb)\n",
    "print()\n",
    "\n",
    "f1_score_train_nb = metrics.f1_score(y_train,y_train_nb, average='macro')\n",
    "f1_score_test_nb = metrics.f1_score(y_test,y_test_nb, average='macro')\n",
    "print(\"Naive Bayes Classifier : f1_score on training Data: \",f1_score_train_nb)\n",
    "print(\"Naive Bayes Classifier : f1_score on test Data: \",f1_score_test_nb)\n",
    "print()\n",
    "\n",
    "recall_score_train_nb = metrics.recall_score(y_train,y_train_nb, average='macro')\n",
    "recall_score_test_nb = metrics.recall_score(y_test,y_test_nb, average='macro')\n",
    "print(\"Naive Bayes Classifier : Recall on training Data: \",recall_score_train_nb)\n",
    "print(\"Naive Bayes Classifier : Recall on test Data: \",recall_score_test_nb)\n",
    "print()\n",
    "\n",
    "precision_score_train_nb = metrics.precision_score(y_train,y_train_nb, average='macro')\n",
    "precision_score_test_nb = metrics.precision_score(y_test,y_test_nb, average='macro')\n",
    "print(\"Naive Bayes Classifier : precision on training Data: \",precision_score_train_nb)\n",
    "print(\"Naive Bayes Classifier : precision on test Data: \",precision_score_test_nb)\n",
    "\n",
    "EER_nb =\"{:.4f}\".format(mean_squared_error(y_test, y_test_nb))\n",
    "time= time.clock() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "\n",
    "storeResults('Naive Bayes Classifier',acc_test_nb,EER_nb,time,f1_score_test_nb,\n",
    "             recall_score_train_nb,precision_score_train_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=30, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree Classifier model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate the model \n",
    "tree = DecisionTreeClassifier(max_depth=30)\n",
    "\n",
    "# fit the model \n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "import time\n",
    "y_train_tree = tree.predict(X_train)\n",
    "start_time= time.clock()\n",
    "y_test_tree = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
    "\n",
    "acc_train_tree = metrics.accuracy_score(y_train,y_train_tree)\n",
    "acc_test_tree = metrics.accuracy_score(y_test,y_test_tree)\n",
    "\n",
    "f1_score_train_tree = metrics.f1_score(y_train,y_train_tree, average='macro')\n",
    "f1_score_test_tree = metrics.f1_score(y_test,y_test_tree, average='macro')\n",
    "\n",
    "recall_score_train_tree = metrics.recall_score(y_train,y_train_tree, average='macro')\n",
    "recall_score_test_tree = metrics.recall_score(y_test,y_test_tree, average='macro')\n",
    "\n",
    "precision_score_train_tree = metrics.precision_score(y_train,y_train_tree, average='macro')\n",
    "precision_score_test_tree = metrics.precision_score(y_test,y_test_tree, average='macro')\n",
    "\n",
    "EER_tree =\"{:.4f}\".format(mean_squared_error(y_test, y_test_tree))\n",
    "time= time.clock() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "\n",
    "storeResults('Decision Tree',acc_test_tree,EER_tree,time,f1_score_test_tree,\n",
    "             recall_score_train_tree,precision_score_train_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# instantiate the model\n",
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fit the model \n",
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "import time\n",
    "y_train_forest = forest.predict(X_train)\n",
    "start_time= time.clock()\n",
    "y_test_forest = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest : Accuracy on training Data:  1.0\n",
      "Random Forest : Accuracy on test Data:  0.9966517857142857\n",
      "\n",
      "Random Forest : f1_score on training Data:  1.0\n",
      "Random Forest : f1_score on test Data:  0.99667190434606\n",
      "\n",
      "Random Forest : Recall on training Data:  1.0\n",
      "Random Forest : Recall on test Data:  0.9966688772459037\n",
      "\n",
      "Random Forest : precision on training Data:  1.0\n",
      "Random Forest : precision on test Data:  0.9967113917583733\n"
     ]
    }
   ],
   "source": [
    "#computing the accuracy, f1_score, Recall, precision of the model performance\n",
    "\n",
    "acc_train_forest = metrics.accuracy_score(y_train,y_train_forest)\n",
    "acc_test_forest = metrics.accuracy_score(y_test,y_test_forest)\n",
    "print(\"Random Forest : Accuracy on training Data: \",acc_train_forest)\n",
    "print(\"Random Forest : Accuracy on test Data: \",acc_test_forest)\n",
    "print()\n",
    "\n",
    "f1_score_train_forest = metrics.f1_score(y_train,y_train_forest, average='macro')\n",
    "f1_score_test_forest = metrics.f1_score(y_test,y_test_forest, average='macro')\n",
    "print(\"Random Forest : f1_score on training Data: \",f1_score_train_forest)\n",
    "print(\"Random Forest : f1_score on test Data: \",f1_score_test_forest)\n",
    "print()\n",
    "\n",
    "recall_score_train_forest = metrics.recall_score(y_train,y_train_forest, average='macro')\n",
    "recall_score_test_forest = metrics.recall_score(y_test,y_test_forest, average='macro')\n",
    "print(\"Random Forest : Recall on training Data: \",recall_score_train_forest)\n",
    "print(\"Random Forest : Recall on test Data: \",recall_score_test_forest)\n",
    "print()\n",
    "\n",
    "precision_score_train_forest = metrics.precision_score(y_train,y_train_forest, average='macro')\n",
    "precision_score_test_forest = metrics.precision_score(y_test,y_test_forest, average='macro')\n",
    "print(\"Random Forest : precision on training Data: \",precision_score_train_forest)\n",
    "print(\"Random Forest : precision on test Data: \",precision_score_test_forest)\n",
    "\n",
    "EER_forest =\"{:.4f}\".format(mean_squared_error(y_test, y_test_forest))\n",
    "time= time.clock() - start_time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing the results. The below mentioned order of parameter passing is important.\n",
    "\n",
    "storeResults('Random Forest',acc_test_forest,EER_forest,time,f1_score_test_forest,\n",
    "             recall_score_train_forest,precision_score_train_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe\n",
    "result = pd.DataFrame({ 'ML Model' : ML_Model,\n",
    "                        'Accuracy' : accuracy,\n",
    "                        'Time'     : Time,\n",
    "                        'EER'      : EER,\n",
    "                        'f1_score' : f1_score,\n",
    "                        'Recall'   : recall,\n",
    "                        'Precision': precision,\n",
    "                      })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting the datafram on accuracy\n",
    "sorted_result=result.sort_values(by=['Accuracy', 'f1_score'],ascending=False).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ML Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Time</th>\n",
       "      <th>EER</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.528241</td>\n",
       "      <td>2.2926</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.992</td>\n",
       "      <td>5.709584</td>\n",
       "      <td>4.3192</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.985</td>\n",
       "      <td>10.518249</td>\n",
       "      <td>4.3192</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.121512</td>\n",
       "      <td>36.4348</td>\n",
       "      <td>0.941</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.508790</td>\n",
       "      <td>51.6261</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes Classifier</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.211129</td>\n",
       "      <td>58.1022</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ML Model  Accuracy       Time      EER  f1_score  Recall  \\\n",
       "0           Random Forest     0.997   0.528241   2.2926     0.997   1.000   \n",
       "1     K-Nearest Neighbors     0.992   5.709584   4.3192     0.992   0.999   \n",
       "2  Support Vector Machine     0.985  10.518249   4.3192     0.986   0.996   \n",
       "3     Logistic Regression     0.940   0.121512  36.4348     0.941   0.955   \n",
       "4           Decision Tree     0.906   0.508790  51.6261     0.905   1.000   \n",
       "5  Naive Bayes Classifier     0.888   0.211129  58.1022     0.889   0.898   \n",
       "\n",
       "   Precision  \n",
       "0      1.000  \n",
       "1      0.999  \n",
       "2      0.996  \n",
       "3      0.955  \n",
       "4      1.000  \n",
       "5      0.901  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dispalying total result\n",
    "sorted_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
